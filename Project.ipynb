{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Class Project: Bilingual Speech Recognition for Personal Assistants**\n",
    "\n",
    "**Project Member:**  \n",
    "Tharnarch Thoranisttakul (Omz), Student ID: 63340500025  \n",
    "FIBO, KMUTT\n",
    "\n",
    "As of now (Apr, 8 2023), the current stable release for DeepSpeech is 0.9.3. Therefore, we will use the DeepSpeech version 0.9.3."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **References:**\n",
    "\n",
    "https://www.section.io/engineering-education/speech-to-text-transcription-model-using-deep-speech/  \n",
    "https://deepspeech.readthedocs.io/en/latest/Python-API.html\n",
    "\n",
    "Audio Sample Durations:  \n",
    "https://stackoverflow.com/questions/42558461/how-long-should-audio-samples-be-for-music-speech-discrimination  \n",
    "https://github.com/NVIDIA/NeMo/issues/1459  \n",
    "https://mozilla.github.io/deepspeech-playbook/DATA_FORMATTING.html  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "from deepspeech import Model\n",
    "from datasets import load_dataset, config, load_from_disk\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import wave\n",
    "import multiprocessing as mp\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from IPython.display import Audio\n",
    "\n",
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading the models and creating alphabet.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepSpeech 0.9.3\n",
    "# Model, Scorer and Alphabet paths\n",
    "model_file_path = 'models/deepspeech-0.9.3-models.pbmm'\n",
    "scorer_file_path = 'models/deepspeech-0.9.3-models.scorer'\n",
    "\n",
    "if not os.path.exists(model_file_path):\n",
    "    # Acoustic Model\n",
    "    !wget -P models https://github.com/mozilla/DeepSpeech/releases/download/v0.9.3/deepspeech-0.9.3-models.pbmm\n",
    "if not os.path.exists(scorer_file_path):\n",
    "    # Language Model\n",
    "    !wget -P models https://github.com/mozilla/DeepSpeech/releases/download/v0.9.3/deepspeech-0.9.3-models.scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/omzlette/miniconda3/envs/bsr/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "/bin/bash: deepspeech-convert: command not found\n"
     ]
    }
   ],
   "source": [
    "!deepspeech-convert --model models/deepspeech-0.9.3-models.pbmm --save_format keras --output_file models/deepspeech-0.9.3-models.h5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/omzlette/miniconda3/envs/bsr/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Requirement already satisfied: deepspeech==0.9.3 in /home/omzlette/miniconda3/envs/bsr/lib/python3.9/site-packages (0.9.3)\n",
      "Requirement already satisfied: numpy>=1.19.4 in /home/omzlette/miniconda3/envs/bsr/lib/python3.9/site-packages (from deepspeech==0.9.3) (1.23.5)\n"
     ]
    }
   ],
   "source": [
    "# Install DeepSpeech 0.9.3 using pip\n",
    "!pip install deepspeech==0.9.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet_path = 'models/alphabet.txt'\n",
    "\n",
    "withTH = False\n",
    "\n",
    "enAlpList = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z',\n",
    "             'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
    "thAlpList = ['ก', 'ข', 'ฃ', 'ค', 'ฅ', 'ฆ', 'ง', 'จ', 'ฉ', 'ช', 'ซ', 'ฌ', 'ญ', 'ฎ', 'ฏ', 'ฐ', 'ฑ', 'ฒ', 'ณ', 'ด', 'ต', 'ถ', 'ท', 'ธ', 'น', 'บ',\n",
    "             'ป', 'ผ', 'ฝ', 'พ', 'ฟ', 'ภ', 'ม', 'ย', 'ร', 'ล', 'ว', 'ศ', 'ษ', 'ส', 'ห', 'ฬ', 'อ', 'ฮ', 'ฯ', 'ะ', 'ั', 'า', 'ำ', 'ิ', 'ี', 'ึ', 'ื', 'ุ', 'ู', 'ฺ',\n",
    "             'เ', 'แ', 'โ', 'ใ', 'ไ', 'ๅ', 'ๆ', '็', '่', '้', '๊', '๋', '์', 'ํ', '๎']\n",
    "sortedAlpList = sorted(enAlpList + thAlpList + [\"'\", '\"', ',', '.', '?', '!']) if withTH else sorted(enAlpList + [\"'\", '\"', ',', '.', '?', '!'])\n",
    "\n",
    "# Generate alphabet.txt (Every time so it's the correct one)\n",
    "with open(alphabet_path, 'w') as f:\n",
    "    for i in sortedAlpList:\n",
    "        f.write(i + '\\n')\n",
    "    f.write(' ')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/omzlette/miniconda3/envs/bsr/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid.\n",
      "Your token has been saved to /home/omzlette/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the latest cached version of the module from /home/omzlette/BSR-Project/data/modules/datasets_modules/datasets/mozilla-foundation--common_voice_12_0/dd534e3c6006ee4b577c176df4a8ef23bced8b3150a3b64d2d0a7a5e3f942efb (last modified on Sun Apr  9 22:05:18 2023) since it couldn't be found locally at mozilla-foundation/common_voice_12_0., or remotely on the Hugging Face Hub.\n",
      "Found cached dataset common_voice_12_0 (/home/omzlette/BSR-Project/data/datasets/mozilla-foundation___common_voice_12_0/en/12.0.0/dd534e3c6006ee4b577c176df4a8ef23bced8b3150a3b64d2d0a7a5e3f942efb)\n"
     ]
    }
   ],
   "source": [
    "# Login to HuggingFace\n",
    "!huggingface-cli login --token=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\n",
    "\n",
    "# Set download path and cache path\n",
    "config.DOWNLOADED_DATASETS_PATH = \"/media/omzlette/2ndSSD/CommonVoice_Corpus/data\"\n",
    "config.HF_CACHE_HOME = os.path.expanduser(\"~/BSR-Project/data\")\n",
    "config.HF_DATASETS_CACHE = os.path.join(config.HF_CACHE_HOME, \"datasets\")\n",
    "config.HF_METRICS_CACHE = os.path.join(config.HF_CACHE_HOME, \"metrics\")\n",
    "config.HF_MODULES_CACHE = os.path.join(config.HF_CACHE_HOME, \"modules\")\n",
    "\n",
    "en_cv13 = load_dataset(\"mozilla-foundation/common_voice_12_0\", \"en\", split='train')\n",
    "# th_cv13 = load_dataset(\"mozilla-foundation/common_voice_13_0\", \"th\", split=\"train\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to various references above on duration of audio samples and the DeepSpeech Playbook itself, having too short or too long audio samples for training will make our model less accurate. However, before we clean up our data, we will check whether the data has duration specified or not. If not, then we will check the sampling rate if they are the same or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'client_id': Value(dtype='string', id=None),\n",
       " 'path': Value(dtype='string', id=None),\n",
       " 'audio': Audio(sampling_rate=48000, mono=True, decode=True, id=None),\n",
       " 'sentence': Value(dtype='string', id=None),\n",
       " 'up_votes': Value(dtype='int64', id=None),\n",
       " 'down_votes': Value(dtype='int64', id=None),\n",
       " 'age': Value(dtype='string', id=None),\n",
       " 'gender': Value(dtype='string', id=None),\n",
       " 'accent': Value(dtype='string', id=None),\n",
       " 'locale': Value(dtype='string', id=None),\n",
       " 'segment': Value(dtype='string', id=None)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_cv13.features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "986897"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_cv13.shape[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like the sampling rate is at 48000. However, in this case, we will present another way to check the sampling rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_sampling_rates = set()\n",
    "\n",
    "# def update_unique_sampling_rates(batch):\n",
    "#     for audio in batch['audio']:\n",
    "#         unique_sampling_rates.add(audio['sampling_rate'])\n",
    "\n",
    "# en_cv13.map(update_unique_sampling_rates, batched=True, batch_size=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_sampling_rates"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result, every audio file's sampling rate is 48000.\n",
    "\n",
    "![Unique Sampling Rates EN](https://github.com/omzlette/BSR-EN-TH/blob/main/pic/unique_sampling_rate_en.png?raw=true)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since, the dataset already gave us the audio array and the sampling rate. We can use it to calculate the <u>duration</u> using the **length of the array divided by the sampling rate**.\n",
    "\n",
    "Here's the code for calculating and creating a new duration feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_duration(batch):\n",
    "#     batch['duration'] = np.array([data['array'].shape[0]/data['sampling_rate'] for data in batch['audio']])\n",
    "#     return batch\n",
    "\n",
    "# en_cv13 = en_cv13.map(calculate_duration, batched=True, batch_size=500)\n",
    "\n",
    "# en_cv13[0]['duration']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try plotting a histogram of the audio arrays' length to help us decide where to cut out our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /home/omzlette/BSR-Project/data/datasets/mozilla-foundation___common_voice_12_0/en/12.0.0/dd534e3c6006ee4b577c176df4a8ef23bced8b3150a3b64d2d0a7a5e3f942efb/cache-4f15766be8eb3fcb.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([3.0960e+03, 3.5640e+04, 4.3803e+04, 1.5341e+04, 2.1040e+03,\n",
       "        4.0000e+00, 6.0000e+00, 4.0000e+00, 1.0000e+00, 1.0000e+00]),\n",
       " array([  48384. ,  147225.6,  246067.2,  344908.8,  443750.4,  542592. ,\n",
       "         641433.6,  740275.2,  839116.8,  937958.4, 1036800. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sampleSize = 100000\n",
    "sampleData = en_cv13.shuffle(seed=2).select(range(sampleSize))\n",
    "\n",
    "plt.hist([len(sample['audio']['array']) for sample in sampleData])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we know that our audio's sampling rate are 48000, so we can create a condition to remove audio instances directly using audio arrays' length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfa25fcc7d3548938fd3e1df6f300552",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/986897 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "635070"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lowerLim = 48_000 * 5\n",
    "# upperLim = 48_000 * 30\n",
    "\n",
    "# en_cv13 = en_cv13.filter(lambda x: lowerLim <= x['audio']['array'].shape[0] <= upperLim)\n",
    "# en_cv13.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "489bd9167bdc46d48cb9ae8e9c204277",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/53 shards):   0%|          | 0/635070 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# en_cv13.save_to_disk(\"data/en_cv13_filtered5-30s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_cv13 = load_from_disk(\"data/en_cv13_filtered5-30s\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model Training**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize hyperparameters variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters Variables\n",
    "\"\"\"According to the DeepSpeech documentation, \n",
    "a larger beam width value generates better results \n",
    "at the cost of decoding time.\"\"\"\n",
    "beam_width = 100\n",
    "lm_alpha = 0.75\n",
    "lm_beta = 1.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TensorFlow: v2.3.0-6-g23ad988\n",
      "DeepSpeech: v0.9.3-0-gf2e9c85\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimize lm_alpha and lm_beta\n",
    "# https://deepspeech.readthedocs.io/en/v0.9.3/Scorer.html\n",
    "\n",
    "# Code:\n",
    "# Load model into memory\n",
    "model = Model(model_file_path)\n",
    "model.enableExternalScorer(scorer_file_path)\n",
    "\n",
    "# Set hyperparameters\n",
    "model.setScorerAlphaBeta(lm_alpha, lm_beta)\n",
    "model.setBeamWidth(beam_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe(audio_file):\n",
    "    fin = wave.open(audio_file, 'rb')\n",
    "    audio = np.frombuffer(fin.readframes(fin.getnframes()), np.int16)\n",
    "    text = model.stt(audio)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe(audio_file):\n",
    "    # Process audio file\n",
    "    data16, rate = process_audio(audio_file)\n",
    "\n",
    "    # Transcribe audio file\n",
    "    return model.stt(data16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bsr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
